{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstrate Seq2Seq Wrapper with twitter chat log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data_utils' from 'D:\\\\UCSD\\\\W17\\\\CSE253\\\\Project\\\\storyteller\\\\data_utils.py'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import importlib\n",
    "\n",
    "# preprocessed data\n",
    "from dataset import data\n",
    "import data_utils\n",
    "importlib.reload(data_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data from pickle and npy files\n",
    "metadata, idx_p, idx_x, idx_a = data.load_data(PATH='dataset/')\n",
    "(trainP, trainX, trainA), (testP, testX, testA), (validP, validX, validA) = data_utils.split_dataset(idx_p, idx_x, idx_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17973, 17973, 17973)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testP), len(testX), len(testA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lengths=[20,]\n",
    "\n",
    "for lenght in lengths:\n",
    "    trainX\n",
    "    trainA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parameters \n",
    "xseq_len = trainX.shape[-1]\n",
    "yseq_len = trainA.shape[-1]\n",
    "batch_size = 16\n",
    "xvocab_size = len(metadata['idx2w'])  \n",
    "yvocab_size = xvocab_size\n",
    "emb_dim = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(small_trainX, small_trainY) = (trainX[:1000], trainA[:1000])\n",
    "(small_testX, small_testY) = (testX[:100], testA[:100]) \n",
    "(small_validX, small_validY) = (validX[:100], validA[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seq2seq_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'seq2seq_wrapper' from 'D:\\\\UCSD\\\\W17\\\\CSE253\\\\Project\\\\practical_seq2seq-master\\\\practical_seq2seq-master\\\\seq2seq_wrapper.py'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(seq2seq_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<log> Building Graph </log>"
     ]
    }
   ],
   "source": [
    "model = seq2seq_wrapper.Seq2Seq(xseq_len=xseq_len,\n",
    "                               yseq_len=yseq_len,\n",
    "                               xvocab_size=xvocab_size,\n",
    "                               yvocab_size=yvocab_size,\n",
    "                               ckpt_path='ckpt/',\n",
    "                               emb_dim=emb_dim,\n",
    "                               num_layers=1,\n",
    "                                epochs=100\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_batch_gen = data_utils.rand_batch_gen(small_validX, small_validY, 100)\n",
    "test_batch_gen = data_utils.rand_batch_gen(small_testX, small_testY, 100)\n",
    "train_batch_gen = data_utils.rand_batch_gen(small_trainX, small_trainY, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<log> Training started </log>\n",
      "\n",
      "Model saved to disk at iteration #10\n",
      "val   loss : 6.802815\n",
      "\n",
      "Model saved to disk at iteration #20\n",
      "val   loss : 3.901994\n",
      "\n",
      "Model saved to disk at iteration #30\n",
      "val   loss : 3.122030\n",
      "Interrupted by user at iteration 40\n"
     ]
    }
   ],
   "source": [
    "sess = model.train(train_batch_gen, val_batch_gen, sess = sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = model.restore_last_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 30)\n"
     ]
    }
   ],
   "source": [
    "input_ = train_batch_gen.__next__()[0]\n",
    "output = model.predict(sess, input_)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q : [not a girl exactly  maybe seventeen or eighteen years old ]; a : [    ]\n",
      "q : [i liked his laugh ]; a : [     ]\n",
      "q : [and because she wasnt as pretty as her sisters with her plain black hair and plain black eyes  she doubled her efforts to dress herself ]; a : [    ]\n",
      "q : [youre such a pussy ]; a : [     ]\n",
      "q : [i take a moment  letting my eyes rake over him ]; a : [    ]\n",
      "q : [where jakes had been unk  a bit on the curly side  and jetblack  sam got his from laura ]; a : [    ]\n",
      "q : [of his three daughters  it was anya who  despite her unk  made a unk impression ]; a : [    ]\n",
      "q : [welcome to unk resort the words are perfectly carved in a foreign wood above the entrance gate ]; a : [    ]\n",
      "q : [i felt my mouth unk at her actions  but any humor instantly fell away when i shifted and pain seared my neck and shoulder unk ]; a : [    ]\n",
      "q : [ will do  anne ]; a : [     ]\n",
      "q : [unk santa even has a nice happy glow to him and unk looks like hes lost a few pounds ]; a : [    ]\n",
      "q : [he must have known i gave in ]; a : [     ]\n",
      "q : [excuse me  i didnt hear you ]; a : [     ]\n",
      "q : [she heard tyler asking her a question  but her thoughts ran slowly through her brain so she didnt hear what he asked ]; a : [    ]\n",
      "q : [they scanned many unk and earth was their best option for survival ]; a : [    ]\n",
      "q : [she was always gone ]; a : [     ]\n"
     ]
    }
   ],
   "source": [
    "replies = []\n",
    "for ii, oi in zip(input_.T, output):\n",
    "    q = data_utils.decode(sequence=ii, lookup=metadata['idx2w'], separator=' ')\n",
    "    decoded = data_utils.decode(sequence=oi, lookup=metadata['idx2w'], separator=' ').split(' ')\n",
    "    print('q : [{0}]; a : [{1}]'.format(q, ' '.join(decoded)))\n",
    "    if decoded.count('unk') == 0:\n",
    "        if decoded not in replies:\n",
    "            #print('q : [{0}]; a : [{1}]'.format(q, ' '.join(decoded)))\n",
    "            replies.append(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
